features
    "AFNI_Analysis" {abstract}
        optional
            Deconvolve // Performs OLS regression given a 4D neuroimage file and stimulus timings
                optional
                     in_files // filenames of 3D+time input datasets. More than one filename can be given and the datasets will be auto-catenated in time. You can input a 1D time series file here, but the time axis should run along the ROW direction, not the COLUMN direction as in the 'input1D' option.
                     sat // check the dataset time series for initial saturation transients, which should normally have been excised before data analysis.
                     trans // check the dataset time series for initial saturation transients, which should normally have been excised before data analysis.
                     noblock // normally, if you input multiple datasets with 'input', then the separate datasets are taken to be separate image runs that get separate baseline models. Use this options if you want to have the program consider these to be all one big run.* If any of the input dataset has only 1 sub-brick, then this option is automatically invoked!* If the auto-catenation feature isn't used, then this option has no effect, no how, no way.
                     force_TR // use this value instead of the TR in the 'input' dataset. (It's better to fix the input using Refit.)
                     input1D // filename of single (fMRI) .1D time series where time runs down the column.
                     TR_1D // TR to use with 'input1D'. This option has no effect if you do not also use 'input1D'.
                     legendre // use Legendre polynomials for null hypothesis (baseline model)
                     nolegendre // use power polynomials for null hypotheses. Don't do this unless you are crazy!
                     nodmbase // don't de-mean baseline time series
                     dmbase // de-mean baseline time series (default if 'polort' >= 0)
                     svd // use SVD instead of Gaussian elimination (default)
                     nosvd // use Gaussian elimination instead of SVD
                     rmsmin // minimum rms error to reject reduced model (default = 0; don't use this option normally!)
                     nocond // DON'T calculate matrix condition number
                     singvals // print out the matrix singular values
                     goforit // use this to proceed even if the matrix has bad problems (e.g., duplicate columns, large condition number, etc.).
                     allzero_OK // don't consider all zero matrix columns to be the type of error that 'gotforit' is needed to ignore.
                     dname // set environmental variable to provided value
                     mask // filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
                     automask // build a mask automatically from input data (will be slow for long time series datasets)
                     STATmask // build a mask from provided file, and use this mask for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
                     censor // filename of censor .1D time series. This is a file of 1s and 0s, indicating which time points are to be included (1) and which are to be excluded (0).
                     polort // degree of polynomial corresponding to the null hypothesis [default: 1]
                     ortvec // this option lets you input a rectangular array of 1 or more baseline vectors from a file. This method is a fast way to include a lot of baseline regressors in one step.
                     x1D // specify name for saved X matrix
                     x1D_stop // stop running after writing .xmat.1D file
                     cbucket // Name for dataset in which to save the regression coefficients (no statistics). This dataset will be used in a -xrestore run [not yet implemented] instead of the bucket dataset, if possible.
                     out_file // output statistics file
                     num_threads // run the program with provided number of sub-processes
                     fout // output F-statistic for each stimulus
                     rout // output the R^2 statistic for each stimulus
                     tout // output the T-statistic for each stimulus
                     vout // output the sample variance (MSE) for each stimulus
                     nofdr // Don't compute the statistic-vs-FDR curves for the bucket dataset.
                     global_times // use global timing for stimulus timing files
                     local_times // use local timing for stimulus timing files
                     num_stimts // number of stimulus timing files
                     stim_times // generate a response model from a set of stimulus times given in file.
                     stim_label // label for kth input stimulus (e.g., Label1)
                     stim_times_subtract // this option means to subtract specified seconds from each time encountered in any 'stim_times' option. The purpose of this option is to make it simple to adjust timing files for the removal of images from the start of each imaging run.
                     num_glt // number of general linear tests (i.e., contrasts)
                     gltsym // general linear tests (i.e., contrasts) using symbolic conventions (e.g., '+Label1 -Label2')
                     glt_label // general linear test (i.e., contrast) labels
                     outputtype // AFNI output filetype
                        Alternative
                            ['NIFTI', 'AFNI', 'NIFTI_GZ']
                     args // Additional parameters to the command
                     environ // Environment variables
            Remlfit // Performs Generalized least squares time series fit with Restricted
                mandatory
                     in_files // Read time series dataset
                     matrix // the design matrix file, which should have been output from Deconvolve via the 'x1D' option
                optional
                     polort // if no 'matrix' option is given, AND no 'matim' option, create a matrix with Legendre polynomial regressorsup to the specified order. The default value is 0, whichproduces a matrix with a single column of all ones
                     matim // read a standard file as the matrix. You can use only Col as a name in GLTs with these nonstandard matrix input methods, since the other names come from the 'matrix' file. These mutually exclusive options are ignored if 'matrix' is used.
                     mask // filename of 3D mask dataset; only data time series from within the mask will be analyzed; results for voxels outside the mask will be set to zero.
                     automask // build a mask automatically from input data (will be slow for long time series datasets)
                     STATmask // filename of 3D mask dataset to be used for the purpose of reporting truncation-to float issues AND for computing the FDR curves. The actual results ARE not masked with this option (only with 'mask' or 'automask' options).
                     addbase // file(s) to add baseline model columns to the matrix with this option. Each column in the specified file(s) will be appended to the matrix. File(s) must have at least as many rows as the matrix does.
                     slibase // similar to 'addbase' in concept, BUT each specified file must have an integer multiple of the number of slices in the input dataset(s); then, separate regression matrices are generated for each slice, with the first column of the file appended to the matrix for the first slice of the dataset, the second column of the file appended to the matrix for the first slice of the dataset, and so on. Intended to help model physiological noise in FMRI, or other effects you want to regress out that might change significantly in the inter-slice time intervals. This will slow the program down, and make it use a lot more memory (to hold all the matrix stuff).
                     slibase_sm // similar to 'slibase', BUT each file much be in slice major order (i.e. all slice0 columns come first, then all slice1 columns, etc).
                     usetemp // write intermediate stuff to disk, to economize on RAM. Using this option might be necessary to run with 'slibase' and with 'Grid' values above the default, since the program has to store a large number of matrices for such a problem: two for every slice and for every (a,b) pair in the ARMA parameter grid. Temporary files are written to the directory given in environment variable TMPDIR, or in /tmp, or in ./ (preference is in that order)
                     nodmbase // by default, baseline columns added to the matrix via 'addbase' or 'slibase' or 'dsort' will each have their mean removed (as is done in Deconvolve); this option turns this centering off
                     dsort // 4D dataset to be used as voxelwise baseline regressor
                     dsort_nods // if 'dsort' option is used, this command will output additional results files excluding the 'dsort' file
                     fout // output F-statistic for each stimulus
                     rout // output the R^2 statistic for each stimulus
                     tout // output the T-statistic for each stimulus; if you use 'out_file' and do not give any of 'fout', 'tout',or 'rout', then the program assumes 'fout' is activated.
                     nofdr // do NOT add FDR curve data to bucket datasets; FDR curves can take a long time if 'tout' is used
                     nobout // do NOT add baseline (null hypothesis) regressor betas to the 'rbeta_file' and/or 'obeta_file' output datasets.
                     gltsym // read a symbolic GLT from input file and associate it with a label. As in Deconvolve, you can also use the 'SYM:' method to provide the definition of the GLT directly as a string (e.g., with 'SYM: +Label1 -Label2'). Unlike Deconvolve, you MUST specify 'SYM: ' if providing the GLT directly as a string instead of from a file
                     out_file // output dataset for beta + statistics from the REML estimation; also contains the results of any GLT analysis requested in the Deconvolve setup, similar to the 'bucket' output from Deconvolve. This dataset does NOT get the betas (or statistics) of those regressors marked as 'baseline' in the matrix file.
                     var_file // output dataset for REML variance parameters
                     rbeta_file // output dataset for beta weights from the REML estimation, similar to the 'cbucket' output from Deconvolve. This dataset will contain all the beta weights, for baseline and stimulus regressors alike, unless the '-nobout' option is given -- in that case, this dataset will only get the betas for the stimulus regressors.
                     glt_file // output dataset for beta + statistics from the REML estimation, but ONLY for the GLTs added on the REMLfit command line itself via 'gltsym'; GLTs from Deconvolve's command line will NOT be included.
                     fitts_file // output dataset for REML fitted model
                     errts_file // output dataset for REML residuals = data - fitted model
                     wherr_file // dataset for REML residual, whitened using the estimated ARMA(1,1) correlation matrix of the noise
                     quiet // turn off most progress messages
                     verb // turns on more progress messages, including memory usage progress reports at various stages
                     goforit // With potential issues flagged in the design matrix, an attempt will nevertheless be made to fit the model
                     ovar // dataset for OLSQ st.dev. parameter (kind of boring)
                     obeta // dataset for beta weights from the OLSQ estimation
                     obuck // dataset for beta + statistics from the OLSQ estimation
                     oglt // dataset for beta + statistics from 'gltsym' options
                     ofitts // dataset for OLSQ fitted model
                     oerrts // dataset for OLSQ residuals (data - fitted model)
                     num_threads // set number of threads
                     outputtype // AFNI output filetype
                        Alternative
                            ['NIFTI', 'AFNI', 'NIFTI_GZ']
                     args // Additional parameters to the command
                     environ // Environment variables
            Synthesize // Reads a '-cbucket' dataset and a '.xmat.1D' matrix from 3dDeconvolve,
                mandatory
                     cbucket // Read the dataset output from 3dDeconvolve via the '-cbucket' option.
                     matrix // Read the matrix output from 3dDeconvolve via the '-x1D' option.
                     select // A list of selected columns from the matrix (and the corresponding coefficient sub-bricks from the cbucket). Valid types include 'baseline', 'polort', 'allfunc', 'allstim', 'all', Can also provide 'something' where something matches a stim_label from 3dDeconvolve, and 'digits' where digits are the numbers of the select matrix columns by numbers (starting at 0), or number ranges of the form '3..7' and '3-7'.
                optional
                     out_file // output dataset prefix name (default 'syn')
                     dry_run // Don't compute the output, just check the inputs.
                     TR // TR to set in the output. The default value of TR is read from the header of the matrix file.
                     cenfill // Determines how censored time points from the 3dDeconvolve run will be filled. Valid types are 'zero', 'nbhr' and 'none'.
                        Alternative
                            ['zero', 'nbhr', 'none']
                     num_threads // set number of threads
                     outputtype // AFNI output filetype
                        Alternative
                            ['NIFTI', 'AFNI', 'NIFTI_GZ']
                     args // Additional parameters to the command
                     environ // Environment variables
constraints
